{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import torch, os, sys\n",
    "#from deepspeed.ops.adam import FusedAdam\n",
    "from azureml.core import Run\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, RichModelSummary\n",
    "from os.path import join\n",
    "from datasets.mae_datasets import make_dataloaders\n",
    "import argparse\n",
    "from utils.utils import display_environment\n",
    "from utils.openmpi import set_strategy\n",
    "from torch import optim\n",
    "from models.models_mae import mae_vit_huge_patch14_dec512d8b\n",
    "import timm\n",
    "from torch import optim, nn, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import torch, os, sys\n",
    "#from deepspeed.ops.adam import FusedAdam\n",
    "from azureml.core import Run\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, RichModelSummary\n",
    "from os.path import join\n",
    "from datasets.mae_datasets import make_dataloaders\n",
    "import argparse\n",
    "from utils.utils import display_environment\n",
    "from utils.openmpi import set_strategy, OpenMPIClusterEnvironment\n",
    "from torch import optim\n",
    "from models.models_mae import mae_vit_huge_patch14_dec512d8b\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAELightning(LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args       \n",
    "        self.model = mae_vit_huge_patch14_dec512d8b()\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        # Get the images and labels.\n",
    "        X = batch['image']\n",
    "\n",
    "        # Compute the training loss.\n",
    "        loss, _, _ = self.model(X)\n",
    "\n",
    "        # Log the training loss.\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        # Get the images and labels.\n",
    "        X = batch['image']\n",
    "        val_loss, _, _ = self.model(X)\n",
    "       \n",
    "        self.log(\"val_loss\", val_loss.item(), prog_bar=True, sync_dist=True) \n",
    "        \n",
    "        return {\"val_loss\":val_loss.item()}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Make the optimizer and learning rate scheduler.\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), lr=self.args.learning_rate, weight_decay=self.args.weight_decay\n",
    "        )\n",
    "        return [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Args at 0x7f0cddde6fe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    dataset_directory_name=\"azureml://subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/workspaces/gpu-workspace/datastores/workspaceblobstore/paths/UI/2023-12-05_185853_UTC/ImageNet_1000_sm/imagenet-mini/\"\n",
    "    trainset=\"azureml://subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/workspaces/gpu-workspace/datastores/workspaceblobstore/paths/UI/2023-12-05_190730_UTC/ImageNet_1000_train.csv\"\n",
    "    valset=\"azureml://subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/workspaces/gpu-workspace/datastores/workspaceblobstore/paths/UI/2023-12-05_190801_UTC/ImageNet_1000_val.csv\" \n",
    "    num_epochs=100\n",
    "    batch_size=10\n",
    "    num_workers=1\n",
    "    num_nodest=1\n",
    "    num_devices=1\n",
    "    img_size=224\n",
    "    strategy=\"ddp\"\n",
    "    experiment_name=\"minizilla_00\"\n",
    "    precision=32\n",
    "    learning_rate=1e-4\n",
    "    weight_decay=0\n",
    "    num_nodes=1\n",
    "\n",
    "args = Args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PL_GLOBAL_SEED=102938\n",
      "env: PL_SEED_WORKERS=1\n",
      "env: AZ_BATCH_MASTER_NODE=127.0.0.1:6000\n",
      "env: AZ_BATCHAI_MPI_MASTER_NODE=127.0.0.1\n",
      "env: MASTER_ADDR=127.0.0.1\n",
      "env: MASTER_ADDRESS=\n",
      "env: MASTER_PORT=6105\n",
      "env: RANK=0\n",
      "env: NODE_RANK=0\n",
      "env: LOCAL_RANK=0\n",
      "env: GLOBAL_RANK=\n",
      "env: WORLD_SIZE=16\n",
      "env: NCCL_SOCKET_IFNAME=eth0\n",
      "env: OMPI_COMM_WORLD_RANK=0\n",
      "env: OMPI_COMM_WORLD_LOCAL_RANK=0\n",
      "env: OMPI_COMM_WORLD_SIZE=1\n",
      "env: OMPI_COMM_WORLD_LOCAL_SIZE=1\n"
     ]
    }
   ],
   "source": [
    "%env PL_GLOBAL_SEED = 102938\n",
    "%env PL_SEED_WORKERS = 1\n",
    "%env AZ_BATCH_MASTER_NODE = 127.0.0.1:6000\n",
    "%env AZ_BATCHAI_MPI_MASTER_NODE = 127.0.0.1\n",
    "%env MASTER_ADDR = 127.0.0.1\n",
    "%env MASTER_ADDRESS = \n",
    "%env MASTER_PORT = 6105\n",
    "%env RANK = 0\n",
    "%env NODE_RANK = 0\n",
    "%env LOCAL_RANK = 0\n",
    "%env GLOBAL_RANK = \n",
    "%env WORLD_SIZE = 16\n",
    "%env NCCL_SOCKET_IFNAME = eth0\n",
    "%env OMPI_COMM_WORLD_RANK = 0\n",
    "%env OMPI_COMM_WORLD_LOCAL_RANK = 0\n",
    "%env OMPI_COMM_WORLD_SIZE = 1\n",
    "%env OMPI_COMM_WORLD_LOCAL_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 102938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ! Could not connect to the MLFlow tracking uri, please check !\n",
      "creating training and validation sets...\n",
      "Creating dataloaders.......... !!!!!!!!!!!!!!!!!!!!!\n",
      "**********************************************************\n",
      "Trainset:                           filename_fixed\n",
      "0  train/n01440764/n01440764_10043.JPEG\n",
      "1  train/n01440764/n01440764_10470.JPEG\n",
      "2  train/n01440764/n01440764_10744.JPEG\n",
      "3  train/n01440764/n01440764_10845.JPEG\n",
      "4  train/n01440764/n01440764_11170.JPEG\n",
      "Valset:                                 filename_fixed\n",
      "0  val/n01440764/ILSVRC2012_val_00009111.JPEG\n",
      "1  val/n01440764/ILSVRC2012_val_00030740.JPEG\n",
      "2  val/n01440764/ILSVRC2012_val_00046252.JPEG\n",
      "3  val/n01443537/ILSVRC2012_val_00000994.JPEG\n",
      "4  val/n01443537/ILSVRC2012_val_00002241.JPEG\n",
      "!!!!! ********************************************************** !!!!!!!\n",
      "????? ********************************************************** ??????\n",
      "Error loading image azureml://subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/workspaces/gpu-workspace/datastores/workspaceblobstore/paths/UI/2023-12-05_185853_UTC/ImageNet_1000_sm/imagenet-mini/train/n01440764/n01440764_10470.JPEG\n",
      "train_dataset[1] None\n",
      "done\n",
      "creating model...\n",
      "done\n",
      "\n",
      "__main__:\n",
      "----------------------------------------\n",
      "PL_GLOBAL_SEED = 102938\n",
      "PL_SEED_WORKERS = 1\n",
      "AZ_BATCH_MASTER_NODE = 127.0.0.1:6000\n",
      "AZ_BATCHAI_MPI_MASTER_NODE = 127.0.0.1\n",
      "MASTER_ADDR = 127.0.0.1\n",
      "MASTER_ADDRESS = \n",
      "MASTER_PORT = 6105\n",
      "RANK = 0\n",
      "NODE_RANK = 0\n",
      "LOCAL_RANK = 0\n",
      "GLOBAL_RANK = \n",
      "WORLD_SIZE = 16\n",
      "NCCL_SOCKET_IFNAME = eth0\n",
      "OMPI_COMM_WORLD_RANK = 0\n",
      "OMPI_COMM_WORLD_LOCAL_RANK = 0\n",
      "OMPI_COMM_WORLD_SIZE = 1\n",
      "OMPI_COMM_WORLD_LOCAL_SIZE = 1\n",
      "----------------------------------------\n",
      "\n",
      "[2023-12-06 17:48:01,675] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[rank: 0] Global seed set to 102938\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_rank : 0\n",
      "\n",
      "__main__:\n",
      "----------------------------------------\n",
      "PL_GLOBAL_SEED = 102938\n",
      "PL_SEED_WORKERS = 1\n",
      "AZ_BATCH_MASTER_NODE = 127.0.0.1:6000\n",
      "AZ_BATCHAI_MPI_MASTER_NODE = 127.0.0.1\n",
      "MASTER_ADDR = 127.0.0.1\n",
      "MASTER_ADDRESS = \n",
      "MASTER_PORT = 6105\n",
      "RANK = 0\n",
      "NODE_RANK = 0\n",
      "LOCAL_RANK = 0\n",
      "GLOBAL_RANK = \n",
      "WORLD_SIZE = 16\n",
      "NCCL_SOCKET_IFNAME = eth0\n",
      "OMPI_COMM_WORLD_RANK = 0\n",
      "OMPI_COMM_WORLD_LOCAL_RANK = 0\n",
      "OMPI_COMM_WORLD_SIZE = 1\n",
      "OMPI_COMM_WORLD_LOCAL_SIZE = 1\n",
      "----------------------------------------\n",
      "\n",
      "node_rank : 0\n",
      "node_rank : 0\n",
      "main_address : 127.0.0.1\n",
      "main_port : 6000\n",
      "main_port : 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W CUDAFunctions.cpp:108] Warning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (function operator())\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ProcessGroupNCCL is only supported with GPUs, no GPUs found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     num_nodes\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnum_nodes,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     precision\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mprecision\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m display_environment(\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders\u001b[39m=\u001b[39;49mtrain_loader, val_dataloaders\u001b[39m=\u001b[39;49mval_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mtrainer.local_rank: \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mlocal_rank\u001b[39m}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mtrainer.global_rank : \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mglobal_rank\u001b[39m}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mtrainer.world_size : \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mworld_size\u001b[39m}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f37383162303365372d366562372d343530362d626162382d6366336130643839623164342f7265736f7572636547726f7570732f616e746f6e736c7574736b792d72672f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6770752d776f726b73706163652f636f6d70757465732f6d696e696c6c612d696e7374616e6365/home/azureuser/cloudfiles/code/Users/antonslutsky/Minilla/Job_MAE_Modified_Transforms/src/Mae_Trainer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:603\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 603\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    604\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    605\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:645\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    638\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    641\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    644\u001b[0m )\n\u001b[0;32m--> 645\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    647\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[39m# SET UP TRAINING\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: setting up strategy environment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1034\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup_environment()\n\u001b[1;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m   1037\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_setup_hook()  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py:153\u001b[0m, in \u001b[0;36mDDPStrategy.setup_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup_environment\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_distributed()\n\u001b[1;32m    154\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msetup_environment()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/strategies/deepspeed.py:355\u001b[0m, in \u001b[0;36mDeepSpeedStrategy.setup_distributed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_world_ranks()\n\u001b[1;32m    354\u001b[0m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_rank\n\u001b[0;32m--> 355\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_deepspeed_distributed()\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_initialized:\n\u001b[1;32m    357\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_config()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pytorch_lightning/strategies/deepspeed.py:385\u001b[0m, in \u001b[0;36mDeepSpeedStrategy._init_deepspeed_distributed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m     log\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    380\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minitializing deepspeed distributed: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGLOBAL_RANK: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_rank\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMEMBER: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_rank\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworld_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_group_backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_process_group_backend()\n\u001b[0;32m--> 385\u001b[0m deepspeed\u001b[39m.\u001b[39;49minit_distributed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_group_backend, distributed_port\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_environment\u001b[39m.\u001b[39;49mmain_port)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/deepspeed/comm/comm.py:670\u001b[0m, in \u001b[0;36minit_distributed\u001b[0;34m(dist_backend, auto_mpi_discovery, distributed_port, verbose, timeout, init_method, dist_init_required, config, rank, world_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m     utils\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mInitializing TorchBackend in DeepSpeed with backend \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(dist_backend))\n\u001b[1;32m    669\u001b[0m \u001b[39m# Create a torch backend object, initialize torch distributed, and assign to cdb\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m cdb \u001b[39m=\u001b[39m TorchBackend(dist_backend, timeout, init_method, rank, world_size)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/deepspeed/comm/torch.py:120\u001b[0m, in \u001b[0;36mTorchBackend.__init__\u001b[0;34m(self, backend, timeout, init_method, rank, world_size, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m# Future functionality to support ds.initialize() on a single GPU\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# The idea is to fake that dist backend is initialized even when\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# it is not so we can run on a single GPU without doing any init_process_group\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingle_gpu_mode \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_process_group(backend, timeout, init_method, rank, world_size)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/deepspeed/comm/torch.py:146\u001b[0m, in \u001b[0;36mTorchBackend.init_process_group\u001b[0;34m(self, backend, timeout, init_method, rank, world_size)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_process_group\u001b[39m(\u001b[39mself\u001b[39m, backend, timeout, init_method, rank, world_size):\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mdistributed\u001b[39m.\u001b[39mis_initialized():\n\u001b[0;32m--> 146\u001b[0m         torch\u001b[39m.\u001b[39;49mdistributed\u001b[39m.\u001b[39;49minit_process_group(backend,\n\u001b[1;32m    147\u001b[0m                                              timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    148\u001b[0m                                              init_method\u001b[39m=\u001b[39;49minit_method,\n\u001b[1;32m    149\u001b[0m                                              rank\u001b[39m=\u001b[39;49mrank,\n\u001b[1;32m    150\u001b[0m                                              world_size\u001b[39m=\u001b[39;49mworld_size)\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musing_mpi \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributed\u001b[39m.\u001b[39mget_backend() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmpi\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:74\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     73\u001b[0m     t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime_ns()\n\u001b[0;32m---> 74\u001b[0m     func_return \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime_ns()\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m dist\u001b[39m.\u001b[39mis_initialized():\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1148\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[39m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m         \u001b[39m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m         store \u001b[39m=\u001b[39m PrefixStore(\u001b[39m\"\u001b[39m\u001b[39mdefault_pg\u001b[39m\u001b[39m\"\u001b[39m, store)\n\u001b[0;32m-> 1148\u001b[0m     default_pg, _ \u001b[39m=\u001b[39m _new_process_group_helper(\n\u001b[1;32m   1149\u001b[0m         world_size,\n\u001b[1;32m   1150\u001b[0m         rank,\n\u001b[1;32m   1151\u001b[0m         [],\n\u001b[1;32m   1152\u001b[0m         backend,\n\u001b[1;32m   1153\u001b[0m         store,\n\u001b[1;32m   1154\u001b[0m         pg_options\u001b[39m=\u001b[39;49mpg_options,\n\u001b[1;32m   1155\u001b[0m         group_name\u001b[39m=\u001b[39;49mgroup_name,\n\u001b[1;32m   1156\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m   1157\u001b[0m     )\n\u001b[1;32m   1158\u001b[0m     _update_default_pg(default_pg)\n\u001b[1;32m   1160\u001b[0m _world\u001b[39m.\u001b[39mpg_group_ranks[GroupMember\u001b[39m.\u001b[39mWORLD] \u001b[39m=\u001b[39m {i: i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(GroupMember\u001b[39m.\u001b[39mWORLD\u001b[39m.\u001b[39msize())}  \u001b[39m# type: ignore[attr-defined, index]\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1279\u001b[0m, in \u001b[0;36m_new_process_group_helper\u001b[0;34m(group_size, group_rank, global_ranks_in_group, backend, store, pg_options, group_name, timeout, pg_tag)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         pg_options\u001b[39m.\u001b[39mis_high_priority_stream \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m         pg_options\u001b[39m.\u001b[39m_timeout \u001b[39m=\u001b[39m timeout\n\u001b[0;32m-> 1279\u001b[0m     backend_class \u001b[39m=\u001b[39m ProcessGroupNCCL(backend_prefix_store, group_rank, group_size, pg_options)\n\u001b[1;32m   1280\u001b[0m     backend_type \u001b[39m=\u001b[39m ProcessGroup\u001b[39m.\u001b[39mBackendType\u001b[39m.\u001b[39mNCCL\n\u001b[1;32m   1281\u001b[0m \u001b[39melif\u001b[39;00m backend_str \u001b[39m==\u001b[39m Backend\u001b[39m.\u001b[39mUCC \u001b[39mand\u001b[39;00m is_ucc_available():\n\u001b[1;32m   1282\u001b[0m     \u001b[39m# TODO: once UCC plugin is fully deprecated, remove\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[39m# is_ucc_available() from above elif-condition and raise\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[39m# RuntimeError if is_ucc_available() returns false.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ProcessGroupNCCL is only supported with GPUs, no GPUs found!"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch_lightning.strategies import DeepSpeedStrategy\n",
    "\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "# os.environ[\"OMPI_COMM_WORLD_LOCAL_RANK\"] = \"0\"\n",
    "# os.environ[\"OMPI_COMM_WORLD_RANK\"] = \"0\"\n",
    "# os.environ[\"AZ_BATCHAI_MPI_MASTER_NODE\"] = \"127.0.0.1\"\n",
    "\n",
    "\n",
    "# If running on azure, get the active tracking uri and run id\n",
    "# otherwise, use the workspace to get a tracking uri\n",
    "active_run = Run.get_context() #  active run azureml object\n",
    "# offline = False\n",
    "try:\n",
    "    print(active_run.experiment)\n",
    "    tracking_uri=active_run.experiment.workspace.get_mlflow_tracking_uri()\n",
    "    run_id = active_run.id\n",
    "except:\n",
    "    print(f\"WARNING ! Could not connect to the MLFlow tracking uri, please check !\") #offline = True\n",
    "\n",
    "seed_everything(102938, workers = True)\n",
    "\n",
    "print(\"creating training and validation sets...\")\n",
    "train_loader , val_loader = make_dataloaders(args)\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "print(\"creating model...\")\n",
    "model = MAELightning(args=args)\n",
    "print(\"done\")\n",
    "\n",
    "# logger = MLFlowLogger(\n",
    "#             experiment_name=args.experiment_name,\n",
    "#             tracking_uri=tracking_uri,\n",
    "#             run_id=run_id\n",
    "# )\n",
    "\n",
    "display_environment(\"__main__\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", \n",
    "                                        mode=\"min\",\n",
    "                                        save_top_k=999,\n",
    "                                        verbose=True,\n",
    "                                        dirpath=\"./outputs/checkpoints/\",\n",
    "                                        filename=\"{epoch}-{val_loss:.2f}\",\n",
    "                                        save_weights_only=True,\n",
    "                                        auto_insert_metric_name=True)  \n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "model_summary = RichModelSummary(max_depth=1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    num_nodes=args.num_nodes,\n",
    "    accelerator='gpu',\n",
    "    devices=args.num_devices,\n",
    "    log_every_n_steps=1,\n",
    "    logger=None,\n",
    "    num_sanity_val_steps=2,\n",
    "    max_epochs=args.num_epochs,\n",
    "    enable_model_summary=False,\n",
    "    callbacks = [checkpoint_callback,lr_monitor,model_summary],\n",
    "    strategy=DeepSpeedStrategy(\n",
    "            stage = 1,\n",
    "            cluster_environment = OpenMPIClusterEnvironment(devices=args.num_devices)\n",
    "        ),\n",
    "    precision=args.precision\n",
    ")\n",
    "\n",
    "display_environment(\"__main__\")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "print(f\"\"\"trainer.local_rank: {trainer.local_rank}\n",
    "trainer.global_rank : {trainer.global_rank}\n",
    "trainer.world_size : {trainer.world_size}\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
